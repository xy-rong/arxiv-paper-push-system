#!/usr/bin/env python3
"""
arXiv è®ºæ–‡æ¨é€ç³»ç»Ÿ - åŒè¯­Webç‰ˆæœ¬ / arXiv Paper Push System - Bilingual Web Version
æ”¯æŒä¸­è‹±æ–‡ç•Œé¢åˆ‡æ¢çš„Webåº”ç”¨ / Web application with Chinese-English interface switching
"""

from flask import Flask, render_template, request, jsonify, send_file
from flask_cors import CORS
import threading
import os
import tempfile
from datetime import datetime
from typing import List, Dict
import json

from arxiv_fetcher import ArxivFetcher
from summarizer import PaperSummarizer
from report_generator import ReportGenerator
import config

app = Flask(__name__)
CORS(app)

# å…¨å±€å˜é‡ / Global variables
fetcher = ArxivFetcher(max_results=config.MAX_RESULTS)
summarizer = None
reporter = ReportGenerator()

# æ£€æŸ¥OpenAI API / Check OpenAI API
has_openai_api = bool(config.OPENAI_API_KEY)
if has_openai_api:
    try:
        summarizer = PaperSummarizer()
    except Exception as e:
        has_openai_api = False
        print(f"OpenAI API åˆå§‹åŒ–å¤±è´¥ / OpenAI API initialization failed: {e}")

# æœç´¢çŠ¶æ€ / Search status
search_status = {
    'is_searching': False,
    'progress': 0,
    'message': 'å‡†å¤‡å°±ç»ª / Ready',
    'papers': []
}

@app.route('/')
def index():
    """ä¸»é¡µ / Main page"""
    return render_template('bilingual.html', has_openai_api=has_openai_api)

@app.route('/api/search', methods=['POST'])
def search_papers():
    """æœç´¢è®ºæ–‡API / Search papers API"""
    global search_status
    
    if search_status['is_searching']:
        return jsonify({'error': 'æœç´¢æ­£åœ¨è¿›è¡Œä¸­ / Search in progress'}), 400
    
    data = request.json
    keywords_text = data.get('keywords', '').strip()
    
    if not keywords_text:
        return jsonify({'error': 'è¯·è¾“å…¥æœç´¢å…³é”®è¯ / Please enter search keywords'}), 400
    
    keywords = [k.strip() for k in keywords_text.split(',') if k.strip()]
    days = int(data.get('days', 7))
    count = int(data.get('count', 10))
    language = data.get('language', 'chinese')
    
    # é‡ç½®çŠ¶æ€ / Reset status
    search_status.update({
        'is_searching': True,
        'progress': 0,
        'message': 'å¼€å§‹æœç´¢... / Starting search...',
        'papers': []
    })
    
    # æ›´æ–°fetcherçš„æœ€å¤§ç»“æœæ•° / Update fetcher max results
    fetcher.max_results = count
    
    # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œæœç´¢ / Execute search in new thread
    search_thread = threading.Thread(
        target=perform_search,
        args=(keywords, days, language),
        daemon=True
    )
    search_thread.start()
    
    return jsonify({'message': 'æœç´¢å·²å¼€å§‹ / Search started'})

def perform_search(keywords: List[str], days: int, language: str):
    """æ‰§è¡Œæœç´¢çš„åå°ä»»åŠ¡ / Background task for performing search"""
    global search_status
    
    try:
        # æ›´æ–°çŠ¶æ€ / Update status
        search_status.update({
            'progress': 10,
            'message': f'ğŸ” æ­£åœ¨æœç´¢å…³é”®è¯ / Searching keywords: {", ".join(keywords)}'
        })
        
        # æœç´¢è®ºæ–‡ / Search papers
        papers = fetcher.search_papers(keywords, days)
        
        if not search_status['is_searching']:
            return
        
        if not papers:
            search_status.update({
                'is_searching': False,
                'progress': 0,
                'message': 'âŒ æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡ / No relevant papers found',
                'papers': []
            })
            return
        
        search_status.update({
            'progress': 50,
            'message': f'ğŸ“š æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡ï¼Œæ­£åœ¨å¤„ç†æ‘˜è¦... / Found {len(papers)} papers, processing abstracts...'
        })
        
        # ä½¿ç”¨æ‘˜è¦ä½œä¸ºæ€»ç»“ / Use abstracts as summaries
        for i, paper in enumerate(papers):
            if not search_status['is_searching']:
                return
            
            abstract = paper['abstract']
            clean_abstract = fetcher.clean_text(abstract)
            
            # æ ¹æ®è¯­è¨€å¤„ç†æ‘˜è¦ / Process abstract based on language
            if language == 'chinese':
                if len(clean_abstract) > 200:
                    summary = clean_abstract[:200] + "..."
                else:
                    summary = clean_abstract
                summary = f"ã€è®ºæ–‡æ‘˜è¦ã€‘{summary}"
            else:
                if len(clean_abstract) > 300:
                    summary = clean_abstract[:300] + "..."
                else:
                    summary = clean_abstract
                summary = f"[Abstract] {summary}"
            
            paper['summary'] = summary
            
            # æ›´æ–°è¿›åº¦ / Update progress
            progress = 50 + (i + 1) / len(papers) * 40
            search_status['progress'] = progress
        
        if not search_status['is_searching']:
            return
        
        # å®Œæˆæœç´¢ / Complete search
        search_status.update({
            'is_searching': False,
            'progress': 100,
            'message': f'âœ… æœç´¢å®Œæˆï¼æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡ / Search completed! Found {len(papers)} relevant papers',
            'papers': papers
        })
        
    except Exception as e:
        search_status.update({
            'is_searching': False,
            'progress': 0,
            'message': f'âŒ æœç´¢å‡ºé”™ / Search error: {str(e)}',
            'papers': []
        })

@app.route('/api/status')
def get_status():
    """è·å–æœç´¢çŠ¶æ€ / Get search status"""
    return jsonify(search_status)

@app.route('/api/stop')
def stop_search():
    """åœæ­¢æœç´¢ / Stop search"""
    global search_status
    search_status['is_searching'] = False
    search_status['message'] = 'æœç´¢å·²åœæ­¢ / Search stopped'
    return jsonify({'message': 'æœç´¢å·²åœæ­¢ / Search stopped'})

@app.route('/api/download/<format_type>')
def download_report(format_type):
    """ä¸‹è½½æŠ¥å‘Š / Download report"""
    if not search_status['papers']:
        return jsonify({'error': 'æ²¡æœ‰å¯ä¸‹è½½çš„æŠ¥å‘Š / No report available for download'}), 400
    
    try:
        # ä»è¯·æ±‚å‚æ•°è·å–å…³é”®è¯ / Get keywords from request parameters
        keywords_text = request.args.get('keywords', '')
        keywords = [k.strip() for k in keywords_text.split(',') if k.strip()]
        
        if format_type == 'html':
            content = reporter.generate_html_report(search_status['papers'], keywords)
            filename = f"arxiv_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            mimetype = 'text/html'
        else:
            content = reporter.generate_markdown_report(search_status['papers'], keywords)
            filename = f"arxiv_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
            mimetype = 'text/markdown'
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ / Create temporary file
        with tempfile.NamedTemporaryFile(mode='w', suffix=f'.{format_type}', delete=False, encoding='utf-8') as f:
            f.write(content)
            temp_path = f.name
        
        return send_file(
            temp_path,
            as_attachment=True,
            download_name=filename,
            mimetype=mimetype
        )
        
    except Exception as e:
        return jsonify({'error': f'ä¸‹è½½å¤±è´¥ / Download failed: {str(e)}'}), 500

if __name__ == '__main__':
    print("ğŸŒ å¯åŠ¨ arXiv è®ºæ–‡æ¨é€ç³»ç»Ÿ åŒè¯­Webç‰ˆæœ¬... / Starting arXiv Paper Push System Bilingual Web Version...")
    print(f"ğŸ“Š OpenAI API çŠ¶æ€ / OpenAI API Status: {'âœ… å·²é…ç½® / Configured' if has_openai_api else 'âš ï¸ æœªé…ç½® / Not configured'}")
    print("ğŸŒ è®¿é—®åœ°å€ / Access URL: http://localhost:52947")
    print("ğŸ”„ æ”¯æŒä¸­è‹±æ–‡ç•Œé¢åˆ‡æ¢ / Supports Chinese-English interface switching")
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨ / Press Ctrl+C to stop server")
    
    app.run(host='0.0.0.0', port=52948, debug=False)